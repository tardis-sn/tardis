{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c256186f",
   "metadata": {},
   "source": [
    "# Converting Arepo snapshots to be usable by TARDIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ffa8ca",
   "metadata": {},
   "source": [
    "### What is [Arepo](https://arepo-code.org/)?\n",
    "> *Arepo is a massively parallel gravity and magnetohydrodynamics code for astrophysics, designed for problems of large dynamic range. It employs a finite-volume approach to discretize the equations of hydrodynamics on a moving Voronoi mesh, and a tree-particle-mesh method for gravitational interactions. Arepo is originally optimized for cosmological simulations of structure formation, but has also been used in many other applications in astrophysics.*\n",
    "\n",
    "<cite data-cite=\"Weinberger2020\">(Weinberger, 2020)</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3a256",
   "metadata": {},
   "source": [
    "This parser is intended for loading Arepo output files ('snapshots'), extracting the relevant (line-of-sight dependent) data and exporting it to `csvy` files, which can in turn be used in TARDIS models ([see CSVY model](../index.rst#csvy-model))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea3fbc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "\n",
    "Note\n",
    "\n",
    "\n",
    "This parser has been developed for the (not publically available) development version of Arepo, not the public version. Althought it should also work with snapshots from the public version, this has not been tested. If you run into trouble loading the snapshot using the built-in functions, try providing the data manually.    \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tardis.io.parsers import arepo\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef575f3",
   "metadata": {},
   "source": [
    "### Loading the simulation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fbaf7",
   "metadata": {},
   "source": [
    "As a first step, the relevant data has to be loaded from an Arepo snapshot, i.e. an output file of Arepo. In case you have the arepo-snap-util package installed, you can use the built in wrapper (as described below) to load the relevant data. In case you do not have this package installed or want to load the snapshot in a different way, you can manually provide the relevant data and continue with the next step.\n",
    "\n",
    "If you're using the built-in tool, you will need to provide the path to the snapshot file, a list with the elements you want to include in your TARDIS model, as well as the species file with which the Arepo simulation was run. *(The species file should contain one header line, followed by two colums, where the first contains the names of all the species and is used to find the indices of the individual species within the snapshot. The second column is not used by the loader.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb8ab5",
   "metadata": {},
   "source": [
    "In case you have the arepo-snap-util package installed, you can load the data directly from a snapshot:\n",
    "```python\n",
    "snapshot = arepo.ArepoSnapshot(\n",
    "    \"arepo_snapshot.hdf5\", [\"ni56\", \"si28\"], \"species55.txt\", resolution=32\n",
    ")\n",
    "pos, vel, rho, xnuc, time = snapshot.get_grids()\n",
    "```\n",
    "This will load the necessary from the snapshot. See the [API](../../../../../api/tardis.io.parsers.arepo.rst) documentation for more options on how to load snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49203e1f",
   "metadata": {},
   "source": [
    "This will fail with an error if you do not have the arepo-snap-util package installed. Since this is not a default dependency of TARDIS, lets manually load the data. *(This manual load can effectively be used to load all kinds of models unrelated to Arepo, as long as the data comes in the correct format.)*\n",
    "\n",
    "In this case the data is loaded from a `json` file. This file has been created manually by dumping the data which would have been loaded from the snapshot to a `json` file. *(The `json` file is only an example and more for illustrative purposes. As long as the data is provided in the correct format (see below) it is up to the user how it is saved/loaded.)*\n",
    "<details> \n",
    "<summary>Code: (<i>click to expand</i>) </summary>\n",
    "    \n",
    "```python\n",
    "data = {\n",
    "    \"pos\" : pos.tolist(),\n",
    "    \"vel\" : vel.tolist(),\n",
    "    \"rho\" : rho.tolist(),\n",
    "    \"xnuc\": [xnuc[x].tolist() for x in list(xnuc.keys())],\n",
    "    \"time\": time,\n",
    "}\n",
    "json_string = json.dumps(data)\n",
    "with open('arepo_snapshot.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arepo_snapshot.json') as json_file:\n",
    "    data = json.loads(json.load(json_file))\n",
    "\n",
    "# The following lines only parse the .json file. You might not need this depending on how you saved \n",
    "# the snapshot data  \n",
    "pos, vel, rho, nucs, time = data[\"pos\"], data[\"vel\"], data[\"rho\"], data[\"xnuc\"], data[\"time\"]\n",
    "pos = np.array(pos)\n",
    "vel = np.array(vel)\n",
    "rho = np.array(rho)\n",
    "\n",
    "# The nuclear data should be in a dict where each element has its own entry (with the key being the element name)\n",
    "xnuc = {\n",
    "    \"ni56\" : np.array(nucs[0]),\n",
    "    \"si28\" : np.array(nucs[1]),\n",
    "}\n",
    "\n",
    "print(\"Position data shape: \", pos.shape)\n",
    "print(\"Velocity data shape: \", vel.shape)\n",
    "print(\"Density data shape: \", rho.shape)\n",
    "print(\"Nuclear data shape (per element): \", xnuc[\"ni56\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76522979",
   "metadata": {},
   "source": [
    "In case you want to load the snapshot data itself with your own tools, you will need to provide the following data:\n",
    "- Position in the center of mass frame (\"pos\") -> `np.array`\n",
    "- Velocity (\"vel\") -> `np.array`\n",
    "- Density (\"rho\") -> `np.array`\n",
    "- Nuclear fraction (\"xnuc\") of each element you want to include -> `dict` containing `np.array`   \n",
    "- Time of the snapshot (\"time\") -> `float`\n",
    "\n",
    "The data is expected to be mapped to a Carthesian grid and should have the same shape as the one provided by the built-in tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82ae2e",
   "metadata": {},
   "source": [
    "### Extracting a profile and converting it to a csvy file\n",
    "Now You can create a TARDIS model. There are three possibilities on how to extract the profiles from the snapshot:  \n",
    "  \n",
    "- **Line profile**: This extracts the data along a straight line (the x-axis)   \n",
    "- **Cone profile**: This extracts the data within a specified cone  \n",
    "- **Full profile**: This averages over the whole simulation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf051ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = arepo.ConeProfile(pos, vel, rho, xnuc, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7d48d",
   "metadata": {},
   "source": [
    "This loads the data (in this example for a cone profile), which can then be cut to the ranges which you want to include in your TARDIS model. The syntax for the other profiles is similar:  \n",
    "  \n",
    "- `arepo.LineProfile(<args>)`  \n",
    "- `arepo.FullProfile(<args>)`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfe94f",
   "metadata": {},
   "source": [
    "Next you can create the profiles acccording to the model option you selected. A diagnostic plot will be shown per default, but this behaviour can be turned off with the option `show_plot=False`. The plot will always show both the positve and negative axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2286b2",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "\n",
    "Note\n",
    "\n",
    "\n",
    "The keyword ``opening_angle=40`` is only needed for the cone profile. The other modes do not accept this keyword! The angle itself is the opening angle of the full cone and NOT the angle between the central x-axis and the cone!\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa59e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.create_profile(opening_angle=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619b5d0",
   "metadata": {},
   "source": [
    "In many cases you only want a very specific region from the snapshot, e.g. cutting out the dense, optically thick regions. This can be acchieved using the keywords `inner_radius` and `outer_radius`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd934289",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.create_profile(opening_angle=40, inner_radius=1e11, outer_radius=2e11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6310ec",
   "metadata": {},
   "source": [
    "Once you have created a profile of the desired region, you can export the profile to a `csvy` using the commented-out code below, which in turn can be used in a TARDIS model. Here you have to specify how many shells you want to export. The profiles are rebinned using [Scipys binned_statistic function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binned_statistic.html), using the mean value of the data in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.export(20, \"snapshot_converted_to_tardis.csvy\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478ccec",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "By default, the `export` method will not overwrite existing files with the same file name. Setting `overwrite=True` allows overwriting -- for example, if `overwrite=True`, if you make changes and rerun the export your exported file will be updated without creaing an additional file.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e8922",
   "metadata": {},
   "source": [
    "During the export, the `yaml` header is automatically written and includes the time of the screenshot as the time for both the nuclear data as well as the density profile. Per default, the positive axis will be exported. the negative axis can be exported with `direction=\"neg\"`.\n",
    "\n",
    "All abundences will normalised such that roughly sum to 1, but slight deviations are expected to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ec37b",
   "metadata": {},
   "source": [
    "### Manually rebinning the data\n",
    "Using `profile.rebin(<nshells>, statistic=<statistic>)`, you can manually rebin the data and use all `<statistic>` keywords accepted by the `scipy.stats.binned_statistic` function. In this case you should pass the `statistic=None` keyword to the `export` function, so the data does not get rebinned twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.create_profile(opening_angle=40, inner_radius=1e11, outer_radius=2e11, show_plot=False)\n",
    "profile.rebin(20)\n",
    "profile.plot_profile()\n",
    "plt.show()\n",
    "profile.export(20, \"rebinned_snapshot_converted_to_tardis.csvy\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49c11a",
   "metadata": {},
   "source": [
    "## Using the parser as a command line tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0302a53",
   "metadata": {},
   "source": [
    "You can also use the `tardis.io.arepo` package as a command line utility, e.g. if you are running batch jobs and want to automatically convert your snapshots from within you job-script.\n",
    "\n",
    "To export the same profile as in the example above you can run:\n",
    "```bash\n",
    "python ./<location_of_arepo_parser>/arepo.py snapshot.hdf5 snapshot_converted.csvy -o 40 -n 20 --inner_radius 1e11 --outer_radius 2e11 -e ni56 si28 --save_plot plot.png --resolution 32 --plot_rebinned plot_binned.png\n",
    "```\n",
    "\n",
    "This will also save diagnostic plots of both the raw and rebinned profiles. For more information on how to use the command line tool run:\n",
    "```bash\n",
    "python ./<location_of_arepo_parser>/arepo.py --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f988111",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "\n",
    "Note\n",
    "\n",
    "\n",
    "The command line tool does only work with snapshot files, not with e.g. json files. It is in any case not advised to use json files as an intermediate step, as the become huge for higher resolutions.\n",
    "\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
